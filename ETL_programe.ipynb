{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYvalA5XNSYu"
      },
      "source": [
        "# **Extract Transform Load (ETL) Lab**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seMYRvmeNSYv"
      },
      "source": [
        "## **Objectives**\n",
        "Write a simple ETL program\n",
        "*   Read CSV and JSON file types.\n",
        "*   Extract data from CSV and JSON file types.\n",
        "*   Transform data.\n",
        "*   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IRIWQCrNSYw"
      },
      "source": [
        "### Import the required modules and functions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob                         # this module helps in selecting files \n",
        "import pandas as pd                 # this module helps in processing CSV files\n",
        "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "6g7TnG2qvJLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBN11q4pNSY9"
      },
      "source": [
        "### Download Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aABJiABZNSY-"
      },
      "outputs": [],
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T96S21QNSY_"
      },
      "source": [
        "## Unzip Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYj2plF0NSY_",
        "outputId": "1eef6f49-7ac4-4c49-aede-4f86d1f27287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  datasource.zip\n",
            "  inflating: dealership_data/used_car_prices1.csv  \n",
            "  inflating: dealership_data/used_car_prices2.csv  \n",
            "  inflating: dealership_data/used_car_prices3.csv  \n",
            "  inflating: dealership_data/used_car_prices1.json  \n",
            "  inflating: dealership_data/used_car_prices2.json  \n",
            "  inflating: dealership_data/used_car_prices3.json  \n",
            "  inflating: dealership_data/used_car_prices1.xml  \n",
            "  inflating: dealership_data/used_car_prices2.xml  \n",
            "  inflating: dealership_data/used_car_prices3.xml  \n"
          ]
        }
      ],
      "source": [
        "!unzip datasource.zip -d dealership_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11exk5zHNSY_"
      },
      "source": [
        "## About the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YZKFckHNSY_"
      },
      "source": [
        "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_GxvXMiNSZA"
      },
      "source": [
        "## Set Paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZL1lSzjNSZA"
      },
      "outputs": [],
      "source": [
        "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
        "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
        "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZZRffxUNSZA"
      },
      "source": [
        "# **Extract Phase**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux2lw1MCNSZA"
      },
      "source": [
        "### CSV Extract Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_QKlsL4NSZA"
      },
      "outputs": [],
      "source": [
        "# Add the CSV extract function below\n",
        "def extract_from_csv(file_to_process):\n",
        "    dataframe = pd.read_csv(file_to_process)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnmlCMigNSZB"
      },
      "source": [
        "### JSON Extract Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB9VYY-INSZB"
      },
      "outputs": [],
      "source": [
        "# Add the JSON extract function \n",
        "def extract_from_json(file_to_process):\n",
        "    dataframe = pd.read_json(file_to_process,lines=True)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyXdJKdhNSZC"
      },
      "source": [
        "### XML Extract Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yci-EKFmUu9T"
      },
      "outputs": [],
      "source": [
        "# Add the XML extract function \n",
        "def extract_from_xml(file_to_process):\n",
        "    dataframe = pd.DataFrame(columns=['car_model', 'year_of_manufacture', 'price',  'fuel'])\n",
        "    tree = ET.parse(file_to_process)\n",
        "    root = tree.getroot()\n",
        "    for person in root:\n",
        "        car_model = person.find(\"car_model\").text\n",
        "        year_of_manufacture = float(person.find(\"year_of_manufacture\").text)\n",
        "        price = float(person.find(\"price\").text)\n",
        "        fuel = person.find(\"fuel\").text\n",
        "        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F1KEoG1NSZC"
      },
      "source": [
        "###  Extract Function\n",
        "\n",
        "Call the specific extract created functions above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htl88R6uNSZC"
      },
      "outputs": [],
      "source": [
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
        "    \n",
        "    #process all csv files\n",
        "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
        "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
        "        \n",
        "    #process all json files\n",
        "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
        "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
        "    \n",
        "    #process all xml files\n",
        "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
        "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
        "        \n",
        "    return extracted_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qeh9avfDNSZD"
      },
      "source": [
        "<details><summary>Click here for the solution</summary>\n",
        "\n",
        "```\n",
        "    \n",
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
        "    \n",
        "    #process all csv files\n",
        "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
        "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
        "        \n",
        "    #process all json files\n",
        "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
        "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
        "    \n",
        "    #process all xml files\n",
        "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
        "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
        "        \n",
        "    return extracted_data\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubo_vIT6NSZD"
      },
      "source": [
        "# **Transform Phase**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX6W6X1bNSZD"
      },
      "outputs": [],
      "source": [
        "# Round the price columns to 2 decimal places\n",
        "def transform(data):\n",
        "        data['price'] = round(data.price,2)\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyhQicATNSZE"
      },
      "source": [
        "# **Loading Phase**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-BReXX3NSZE"
      },
      "outputs": [],
      "source": [
        "# Add the load function\n",
        "def load(targetfile,data_to_load):\n",
        "    data_to_load.to_csv(targetfile)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK8ozoAKNSZF"
      },
      "source": [
        "## **Logging**\n",
        "\n",
        "\n",
        "*   Change the name of the logfile to the one specified in the set paths section. \n",
        "*   Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkYqkE0aNSZF"
      },
      "outputs": [],
      "source": [
        "# Add the log function \n",
        "def log(message):\n",
        "    timestamp_format = '%H:%M:%S-%h-%d-%Y' # Hour-Minute-Second-Monthname-Day-Year.\n",
        "    now = datetime.now() # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
        "        f.write(timestamp + ',' + message + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSJLWvrFNSZG"
      },
      "source": [
        "## **Running ETL Process**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWEyfEFQNSZG"
      },
      "source": [
        "###  ETL Process\n",
        "\n",
        "*   Run all functions to extract, transform, and load the data. \n",
        "*   logging all events using the `log` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot0xLKFGNSZG"
      },
      "outputs": [],
      "source": [
        "# Log that the ETL process has started \n",
        "log(\"ETL Job Started\")\n",
        "\n",
        "# Log that the Extract step has started \n",
        "# Call the Extract function\n",
        "# Log that the Extract step have completed\n",
        "\n",
        "log(\"Extract phase Started\")\n",
        "extracted_data = extract()\n",
        "log(\"Extract phase Ended\")\n",
        "\n",
        "\n",
        "# Log that the Transform step has started\n",
        "# Call the Transform function\n",
        "# Log that the Transform step has completed \n",
        "\n",
        "log(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "log(\"Transform phase Ended\")\n",
        "\n",
        "\n",
        "# Log that the Load step has started\n",
        "# Call the Load function\n",
        "# Log that the Load step has completed\n",
        "log(\"Load phase Started\")\n",
        "load(targetfile,transformed_data)\n",
        "log(\"Load phase Ended\")\n",
        "\n",
        "# Log that the ETL process has completed!\n",
        "log(\"ETL Job Ended\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}